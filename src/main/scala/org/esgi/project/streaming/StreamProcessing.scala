package org.esgi.project.streaming

import io.github.azhur.kafkaserdeplayjson.PlayJsonSupport
import org.apache.kafka.streams.KafkaStreams
import org.apache.kafka.streams.kstream.{JoinWindows, TimeWindows, Windowed}
import org.apache.kafka.streams.scala._
import org.apache.kafka.streams.scala.kstream._
import org.esgi.project.streaming.models.{MeanLatencyForURL, Metric, Visit, VisitWithLatency}
import java.io.InputStream
import java.time.Duration
import java.util.Properties

object StreamProcessing extends PlayJsonSupport {

  import org.apache.kafka.streams.scala.ImplicitConversions._
  import org.apache.kafka.streams.scala.serialization.Serdes._

  // TODO: Predeclared store names to be used, fill your first & last name
  val yourFirstName: String = "Saad"
  val yourLastName: String = "MAHI"

  val applicationName = s"web-events-stream-app-$yourFirstName-$yourLastName"
  val visitsTopicName: String = "visits"
  val metricsTopicName: String = "metrics"

  val thirtySecondsStoreName: String = "VisitsOfLast30Seconds"
  val lastMinuteStoreName = "VisitsOfLastMinute"
  val lastFiveMinutesStoreName = "VisitsOfLast5Minutes"

  val thirtySecondsByCategoryStoreName: String = "VisitsOfLast30SecondsByCategory"
  val lastMinuteByCategoryStoreName = "VisitsOfLastMinuteByCategory"
  val lastFiveMinutesByCategoryStoreName = "VisitsOfLast5MinutesByCategory"
  val meanLatencyForURLStoreName = "MeanLatencyForURL"

  val props = buildProperties

  // defining processing graph
  val builder: StreamsBuilder = new StreamsBuilder

  // TODO: declared topic sources to be used
  val visits: KStream[String, Visit] = builder.stream[String, Visit](visitsTopicName)
  val metrics: KStream[String, Metric] = builder.stream[String, Metric](metricsTopicName)

  /**
   * -------------------
   * Part.1 of exercise
   * -------------------
   */
  // TODO: repartition visits per URL
  val visitsGroupedByUrl: KGroupedStream[String, Visit] = visits.groupBy((k,v)=>v.url)

  val window30seconds = Duration.ofSeconds(30)
  val window1minutes = Duration.ofMinutes(1)
  val window5minutes = Duration.ofMinutes(5)

  // TODO: implement a computation of the visits count per URL for the last 30 seconds,
  // TODO: the last minute and the last 5 minutes

  val visitsOfLast30Seconds: KTable[Windowed[String], Long] =
    visitsGroupedByUrl.windowedBy(TimeWindows.of(window30seconds)).count()
  println(visitsOfLast30Seconds)

  val visitsOfLast1Minute: KTable[Windowed[String], Long] =
    visitsGroupedByUrl.windowedBy(TimeWindows.of(window1minutes)).count()
  println(visitsOfLast1Minute)

  val visitsOfLast5Minute: KTable[Windowed[String], Long] =
    visitsGroupedByUrl.windowedBy(TimeWindows.of(window5minutes)).count()
  println(visitsOfLast5Minute)

  /**
   * -------------------
   * Part.2 of exercise
   * -------------------
   */
  // TODO: repartition visits topic per category instead (based on the 2nd part of the URLs)
  val visitsGroupedByCategory: KGroupedStream[String, Visit] = visits.groupBy((k,v) => v.url.split("/")(1))

  // TODO: implement a computation of the visits count per category for the last 30 seconds,
  // TODO: the last minute and the last 5 minutes

  val visitsOfLast30SecondsByCategory: KTable[Windowed[String], Long] =
    visitsGroupedByCategory.windowedBy(TimeWindows.of(window30seconds)).count()
  println(visitsOfLast30SecondsByCategory)

  val visitsOfLast1MinuteByCategory: KTable[Windowed[String], Long] =
    visitsGroupedByCategory.windowedBy(TimeWindows.of(window1minutes)).count()
  println(visitsOfLast1MinuteByCategory)

  val visitsOfLast5MinuteByCategory: KTable[Windowed[String], Long] =
    visitsGroupedByCategory.windowedBy(TimeWindows.of(window5minutes)).count()
  println(visitsOfLast5MinuteByCategory)

  // TODO: implement a join between the visits topic and the metrics topic,
  // TODO: knowing the key for correlated events is currently the same UUID (and the same id field).
  // TODO: the join should be done knowing the correlated events are emitted within a 5 seconds latency.
  // TODO: the outputted message should be a VisitWithLatency object.
  val visitsWithMetrics: kstream.KStream[String, VisitWithLatency] = visits.join(metrics)(
    (visits, metrics) => {
      new VisitWithLatency(visits._id, visits.timestamp, visits.sourceIp, visits.url, metrics.latency)
    },
    JoinWindows.of(Duration.ofSeconds(5))
  )

  // TODO: based on the previous join, compute the mean latency per URL
  val meanLatencyPerUrl: KTable[String, MeanLatencyForURL] = ???

  // -------------------------------------------------------------
  // TODO: now that you're here, materialize all of those KTables
  // TODO: to stores to be able to query them in Webserver.scala
  // -------------------------------------------------------------

  def run(): KafkaStreams = {
    val streams: KafkaStreams = new KafkaStreams(builder.build(), props)
    streams.start()

    // Add shutdown hook to respond to SIGTERM and gracefully close Kafka Streams
    Runtime.getRuntime.addShutdownHook(new Thread(new Runnable() {
      override def run {
        streams.close
      }
    }))
    streams
  }

  // auto loader from properties file in project
  def buildProperties: Properties = {
    import org.apache.kafka.clients.consumer.ConsumerConfig
    import org.apache.kafka.streams.StreamsConfig
    val inputStream: InputStream = getClass.getClassLoader.getResourceAsStream("kafka.properties")

    val properties = new Properties()
    properties.put(StreamsConfig.APPLICATION_ID_CONFIG, applicationName)
    // Disable caching to print the aggregation value after each record
    properties.put(StreamsConfig.CACHE_MAX_BYTES_BUFFERING_CONFIG, "0")
    properties.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "latest")
    properties.put(StreamsConfig.REPLICATION_FACTOR_CONFIG, "-1")
    properties.load(inputStream)
    properties
  }
}
